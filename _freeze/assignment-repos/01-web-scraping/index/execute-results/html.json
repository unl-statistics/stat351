{
  "hash": "6cc8b75dd9875a5edccbd1513887c559",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab: Web Scraping and RSS\"\nauthor: \"Your Name Here\"\nformat: html\nnumber-sections: true\nnumber-depth: 2\n---\n\nThe Securities and Exchange Commission (SEC) provides a way to see the most recent filings submitted to the commission at [https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent](https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent). \n\nForm 144 is required to be submitted when an executive officer, director, or affiliate of the company sells more than 5000 shares of stock or the aggregate sales price exceeds $50,000. \n\nConveniently, we can access the 100 most recent Form 144 filings by using the [RSS feed](https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent&CIK=&type=144&company=&dateb=&owner=include&start=0&count=100&output=atom), which provides some basic information about each filing as well as a link to the filing's database entry. \nAn example of the RSS feed downloaded on July 28, 2025 is provided in the [`sample-feed.rss`](sample-feed.rss) file for demonstration purposes. \n\nRSS feeds are just another XML-like file, as you can see from the [RSS2.0 Specification](https://www.rssboard.org/rss-specification). \n\n::: callout\nYou can see the purpose of this assignment as well as the skills and knowledge you should be using and acquiring, in the [Transparency in Learning and Teaching (TILT)](tilt.qmd) document in this repository. The TILT document also contains a checklist for self-reflection that will provide some guidance as to how the assignment will be graded. \n:::\n\n# Warming Up\n\n## Parsing the File\n\nAdd a code chunk that will read in the RSS feed as an XML file.\n\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(xml2)\nlibrary(rvest)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()         masks stats::filter()\n✖ readr::guess_encoding() masks rvest::guess_encoding()\n✖ dplyr::lag()            masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\ndoc <- read_xml(\"sample-feed.rss\")\nxml_find_first(doc, \"//d1:entry\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{xml_node}\n<entry>\n[1] <title>424B2 - BANK OF NOVA SCOTIA (0000009631) (Filer)</title>\n[2] <link rel=\"alternate\" type=\"text/html\" href=\"https://www.sec.gov/Archives ...\n[3] <summary type=\"html\">\\n &lt;b&gt;Filed:&lt;/b&gt; 2025-07-28 &lt;b&gt;Acc ...\n[4] <updated>2025-07-28T14:47:24-04:00</updated>\n[5] <category scheme=\"https://www.sec.gov/\" label=\"form type\" term=\"424B2\"/>\n[6] <id>urn:tag:sec.gov,2008:accession-number=0001839882-25-040744</id>\n```\n\n\n:::\n\n```{.r .cell-code}\ntmp <- xml_children(doc) |> map(xml_contents)\n\ntmpindex <- map_int(tmp,length)\n\ntmp <- tmp[tmpindex==6]\n\nparse_entries <- function(node) {\n  var_names <- map_chr(node, xml_name)\n  var_values <- map_chr(node, xml_text)\n  \n  res <- as_tibble(t(var_values)) |>\n    set_names(var_names) |>\n    mutate(link = xml_attr(node[[2]], \"href\"),\n           category = xml_attrs(node[[5]]) |> t() |> as_tibble()) |>\n    unnest_wider(category)\n}\n\ntmpdf <- map_dfr(tmp, parse_entries)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n```\n\n\n:::\n:::\n\n\n\n## Extracting Information {#sec-extract-info}\n\nAdd a code chunk that will convert each entry into a data frame row with columns `title`, `link`, `summary`, `updated`, `category`, and `id`. \nNote that you may need to access attributes to get the important data out of some nodes, while for others you may only need to access the content.\n\nShow the first 5 and last 5 rows of your data, using a function like `knitr::kable`, `DT::DT`, or `IPython`'s `display()` and `Markdown()`. See [this page](https://www.datanovia.com/guide/tools/quarto/tables.html#computations) for more information about rendering  \"pretty\" tabular data using quarto. \n\n---\n\n## Is it XML?\n\nIs an RSS feed actually an XML file? Why or why not? What requirements of an XML file does an RSS feed meet, and what requirements are lacking?\n\n---\n\n\n# Cleaning the Data\n\nThe data frame you created in @sec-extract-info is not exactly in tidy form. Let's see if we can fix that!\n\n## Tidy Data\n\nWhat aspects of the data frame need work in order to meet the criteria for tidy data?\n\n---\n\n## Tidy Planning\n\nWrite a step-by-step plan to convert your data into tidy form.\n\n---\n\n## Tidying, for real!\n\nExecute your step-by-step plan. Show a nicely formatted data table with up to 10 entries, and explain why your data is now tidy. \n\n---\n\n# Filing Forms\n\nThe RSS feed provides bare-bones data about SEC filings, but also links to the actual forms. \nThe `link` column of your data should contain a URI for the form which was actually filed. \nLet's work on pulling out the form data, with the idea that we might want to analyze SEC filing data.\n\nFor instance, the following entry describes a tractor supply filing. \n\n```\n<entry>\n<title>144 - TRACTOR SUPPLY CO /DE/ (0000916365) (Subject)</title>\n<link rel=\"alternate\" type=\"text/html\" href=\"https://www.sec.gov/Archives/edgar/data/916365/000195917325004774/0001959173-25-004774-index.htm\"/>\n<summary type=\"html\">\n &lt;b&gt;Filed:&lt;/b&gt; 2025-07-28 &lt;b&gt;AccNo:&lt;/b&gt; 0001959173-25-004774 &lt;b&gt;Size:&lt;/b&gt; 4 KB\n</summary>\n<updated>2025-07-28T14:07:13-04:00</updated>\n<category scheme=\"https://www.sec.gov/\" label=\"form type\" term=\"144\"/>\n<id>urn:tag:sec.gov,2008:accession-number=0001959173-25-004774</id>\n</entry>\n```\n\nThe link URL is [`https://www.sec.gov/Archives/edgar/data/916365/000195917325004774/0001959173-25-004774-index.htm`](https://www.sec.gov/Archives/edgar/data/916365/000195917325004774/0001959173-25-004774-index.htm). On the linked page, there is a table of document format files which contains the same information in HTM(L), XML, and TXT format. \n\n## Preparing\n\nOpen one link from your table and examine the HTML page. \n\n\n1. Identify the CSS selector you believe would be most efficient to obtain the **table** of document format files.\n\n> Your answer here\n\n2. Identify the CSS selector you believe would be most efficient for obtaining the first link in the table of document format files.\n\n> Your answer here\n\n## Reading HTML Tables\n\nWrite a function that takes a URI to the Filing Detail page and extracts the link for the document corresponding to the filing entry (I recommend going for the .htm link).\nUse your function to obtain the HTML addresses of the filed forms for all of the links in your RSS feed.\n\n---\n\n\n## Reading HTML Pages\n\nUse the links to the filed forms and extract the following information from each page, storing the information for each form in a data frame. \n\n- Name, SEC File Number, Address, and Phone Number of Issuer\n- Name of person selling the securities, and relationship to the Issuer\n- Securities Information: all values in the table\n- Securities to be Sold: all values in the table\n- Other sales in the last 3 months, if any\n- Notice date\n\nYou may want to write one or more functions to extract the necessary data, with error handling in order to ensure that if the data does not exist the function still returns the information that is available.\n\n\n---\n\n\n## Assessing Market Value of Stock Sales\n\n\nMake a histogram of the aggregate market value of stock to be sold for the entries in your RSS feed. Make sure your plot has descriptive titles, axis labels, and uses appropriate scales. \n\n---\n\n## Efficiency\n\nImagine you'd saved the RSS feed from the SEC for the past 30 days. \nThe SEC may not receive more than 100 form 144 filings each day, and they do not update the feed on federal holidays or weekends. \n\nDescribe how you would approach generating a database of the unique form 144 filings over all 30 days of RSS feed files. Make an ordered list of steps indicating the order in which you would read in the RSS entries, acquire the corresponding data from the SEC filing form, and deduplicating the potentially repeated filings, along with any other intermediate steps you might take.\n\nYour solution should minimize the amount of load on the SEC's server both because it minimizes the running time of the code and because it's more polite.\n\nCalculate the total number of calls you have to make to the SEC's server to implement your solution, showing your work. \n\n---\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}